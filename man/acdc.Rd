% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/acdc.R
\name{acdc}
\alias{acdc}
\title{The acoustic-centroid depth-contour (ACDC) algorithm}
\usage{
acdc(
  acoustics,
  archival,
  bathy,
  map = NULL,
  detection_range,
  mobility,
  depth_error = 2.5,
  acc_centroids,
  plot = 1L,
  plot_ts = TRUE,
  verbose = TRUE,
  con = "",
  progress = 1L,
  split = NULL,
  cl = NULL,
  ...
)
}
\arguments{
\item{acoustics}{A dataframe, or a list of dataframes, that contains passive acoustic telemetry detection time series (see \code{\link[flapper]{dat_acoustics}} for an example) for a single individual. Each dataframe should contain the following columns: an integer vector of receiver IDs, named 'receiver_id'; a POSIXct vector of time stamps when detections were made, named 'timestamp'; and a numeric vector of those time stamps, named 'timestamp_num'. If a list of dataframes is supplied, these must be refer to the detections of a single individual and be ordered by time (e.g., in hourly chunks). The algorithm will be implemented on each dataframe, termed 'chunk', either in sequence or parallel. Any empty or NULL elements will be removed automatically.}

\item{archival}{A dataframe that contains depth time series (see \code{\link[flapper]{dat_archival}} for an example). This should contain the following columns: a numeric vector of observed depths, named 'depth'; a POSIXct vector of time stamps when observations were made, named 'timestamp'; and a numeric vector of those time stamps, named 'timestamp_num'. Depths should be recorded in the same units and with the same sign as the bathymetry data (see \code{bathy}). Absolute depths (m) are suggested. Unlike the detection time series, archival time stamps are assumed to have occurred at regular intervals. Two-minute intervals are currently assumed.}

\item{bathy}{A \code{\link[raster]{raster}} that defines the bathymetry across the area within which the individual could have moved. This must be recorded in the same units and with the same sign as the depth observations (see \code{archival}). The coordinate reference system should be the Universal Transverse Mercator system, with distances in metres (see also \code{\link[flapper]{acdc_setup_centroids}}).}

\item{map}{(optional) A blank \code{\link[raster]{raster}}, with the same properties (i.e., dimensions, resolution, extent and coordinate reference system) as the bathymetry raster (see \code{bathy}), but in which all values are 0. If \code{NULL}, this is computed internally, but supplying a pre-defined raster can be more computationally efficient if the function is applied iteratively (e.g., over multiple individuals).}

\item{detection_range}{A number that defines the maximum detection range (m) at which an individual could be detected from a receiver (see also \code{\link[flapper]{acdc_setup_centroids}}).}

\item{mobility}{A number that defines the distance (m) that an individual could move in the time period between archival observations (see also \code{\link[flapper]{acdc_setup_centroids}}).}

\item{depth_error}{A number that defines the interval around each depth (m) observation that defines the range of depths on the bathymetry raster (see \code{bathy}) that the individual could plausibly have occupied at that time. For example, \code{depth_error = 2.5} m implies that the individual could have occupied bathymetric cells whose depth lies within the interval defined by the observed depth (m) +/- 2.5 m. The appropriate value for \code{depth_error} depends on measurement error for the archival and bathymetry data, as well as the tidal range (m) across the area.}

\item{acc_centroids}{A list of acoustic centroids, with one element for each number from \code{1:max(acoustics$receiver_id)}, from \code{\link[flapper]{acdc_setup_centroids}}.}

\item{plot}{An integer vector that defines the time steps for which to return the necessary spatial information required to plot the plausible locations of the individual, given detection and depth time series. \code{plot = 0} suppresses the return of this information and \code{plot = NULL} returns this information for all time steps. If the algorithm is applied chunk-wise, this spatial information must be returned for at least the first time step (the default) to aggregate maps across chunks (see \code{\link[flapper]{acdc_simplify}}). This information can also be used to plot time-specific results of the algorithm using \code{\link[flapper]{acdc_plot}} and \code{\link[flapper]{acdc_animate}}.}

\item{plot_ts}{A logical input that defines whether or not to the plot detection and depth time series before the algorithm is initiated. This provides a useful visualisation of the extent to which they overlap.}

\item{verbose}{A logical variable that defines whether or not to print messages to the console or to file to relay function progress. If \code{con = ""}, messages are printed to the console (which is only supported if the algorithm is not implemented in parallel: see below); otherwise, they are written to file (see below).}

\item{con}{If \code{verbose = TRUE}, \code{con} is character string defines how messages relaying function progress are returned. If \code{con = ""}, messages are printed to the console (unless redirected by \code{\link[base]{sink}}), an approach that is only implemented if the function is not implemented in parallel. Otherwise, \code{con} defines the directory into which to write .txt files, into which messages are written to relay function progress. This is approach, rather than printing to the console, is recommended for clarity, speed and debugging. If the algorithm is implemented step-wise, then a single file is written to the specified directory named acdc_log.txt. If the algorithm is implemented chunk-wise, then an additional file is written for each chunk (named dot_acdc_log_1.txt, dot_acdc_log_2.txt and so on), with the details for each chunk.}

\item{progress}{(optional) If the algorithm is implemented step-wise, \code{progress} is an integer (\code{1}, \code{2} or \code{3}) that defines whether or not to display a progress bar in the console as the algorithm moves over acoustic time steps (\code{1}), the archival time steps between each pair of acoustic detections (\code{2}) or both acoustic and archival time steps (\code{3}), in which case the overall acoustic progress bar is punctuated by an archival progress bar for each pair of acoustic detections. This option is useful if there is a large number of archival observations between acoustic detections. Any other input will suppress the progress bar. If the algorithm is implemented for chunks, inputs to \code{progress} are ignored and a single progress bar is shown of the progress across acoustic chunks.}

\item{split}{A character string that defines the time unit used to split acoustic time series into chunks (e.g., \code{"12 hours"}). If provided, this must be supported by \code{\link[lubridate]{floor_date}}. If \code{split = NULL} and a cluster has been specified (see \code{cl}), then the acoustic time series is automatically split into chunks and the algorithm implemented for each chunk in parallel.}

\item{cl}{A cluster object created by \code{\link[parallel]{makeCluster}} to implement the algorithm in parallel. If supplied, the algorithm is implemented for each chunk in a list of acoustic time series as supplied by the user (if \code{acoustics} is a list) or of the time units specified via \code{split} by the user or defined automatically based on the number of nodes in the cluster if \code{split = NULL}.}

\item{...}{Additional arguments (none implemented).}
}
\value{
The function returns an object of class \code{\link[flapper]{acdc-class}}. If a connection to write files has also been specified, an overall log (acdc_log.txt) as well as chunk-specific logs from calls to \code{\link[flapper]{.acdc}}, if applicable, are written to file.
}
\description{
This function implements the acoustic-centroid depth-contour (ACDC) algorithm. This is an approach that integrates acoustic detections and depth observations to infer where benthic/demersal animals could have spent more or less time over the period of observations.

To implement the function, a dataframe (or list) of passive acoustic telemetry detections is required (\code{acoustics}), alongside a dataframe of depth observations (\code{archival}). At each time step, the algorithm integrates information from past and future acoustic detections in the form of acoustic centroids and information from depth observations in the form of depth contours to determine the possible locations of an individual in an area (see Details).

Under the default options, the approach is implemented step-wise (i.e., step-by-step across the whole time series). The result is a named list of outputs, including a record of the results for each time step, as well as a cumulative map of where the individual could have spent more or less time summed across the whole time series. Alternatively, the approach can be implemented chunk-wise, in which case the acoustic time series is split into chunks (e.g., hourly, daily, monthly segments) and the algorithm is implemented within each chunk step-by-step. The main benefits of this approach are that it can be used to reconstruct putative patterns in space use over biologically meaningful periods separately and/or the chunk-wise implementation can be parallelised, improving computation time, while retaining the capacity to combine chunk-wise results easily across the duration of the original time series. This option is implemented if (a) a list, rather than a dataframe, of acoustic detections is provided; (b) the user specifies that the time series should be split into chunks of a particular duration before the algorithm is initiated (via the \code{split} argument); and/or (c) the algorithm is implemented on a cluster via \code{cl}, in which case the acoustic time series is split (if necessary) into user-defined or automatically defined chunks prior to computation. In this case, the result is a named list of outputs, as described above, but in which the results for each chunk are returned separately. If the chunks have been implemented simply to improve computation time via parallelisation, then the maps of space use for each chunk can be combined easily to generate a single, overall map of space use.
}
\details{
The acoustic-centroid depth-contour (ACDC) algorithm is an approach which integrates acoustic detections and depth observations to infer the possible locations of benthic or demersal animals within an area over some time interval. The locational information provided by acoustic detections is represented by acoustic centroids, which are areas around receivers that define where an individual could have been at each timepoint given the spatiotemporal pattern of detections at receivers, a model of detection probability and a movement parameter. The locational information provided by depth observations is represented by depth contours, which are areas that define where an individual could have been at each time point given its depth and the local bathymetry.

In outline, the crux of the approach is the recognition that acoustic detections typically occur irregularly, while archival observations occur at regular intervals. Each detection anchors our knowledge of the location of an individual around a particular receiver (assuming that all detections are true detections). As time passes between acoustic detections, our uncertainty about the geographical location of an individual expands around the receiver at which it was detected before shrinking towards the receiver at which it was next detected. During this time, regular depth observations restrict the number of possible locations in which the individual could have been located at each time step.

More specifically, when an individual is detected, it must be within some radius – say 800 m – of that receiver. This is the starting acoustic centroid. With a more-refined model of detection probability, it may be possible to predict more precisely where the individual is likely to have been within this centroid (but this approach is not yet implemented). The observed depth at this time further restricts the positions in which the individual could have been, assuming a benthic/demersal lifestyle and a non-homogenous bathymetric landscape. Moving forward in time, a number of depth records may be made before another acoustic detection. During this time, our uncertainty about where the individual could have been gets larger, because it could have moved further away from the receiver, so the acoustic centroids that define this uncertainty expand to a maximum size at the halfway point between acoustic detections, excluding areas within the detection radii of other receivers. After that, the individual must have started to move towards the receiver at which it was next detected, so these acoustic centroids start to shrink towards that receiver. If the individual was detected by different receivers, the overlap between the centroids of these two receivers at the halfway point defines the set of positions in which the individual could have been at this time. Thereafter, our uncertainty in the individual’s location is given by the overlap between the expansion of this centroid region and the contraction of the centroid around the receiver at which it was next detected. Thus, when the individual is detected again, our uncertainty about where it could have been collapses to the detection radius around the next receiver, possibly weighted by a model of detection probability around this receiver. The rate of change in centroid size depends a movement parameter that describes an average swimming speed, which will depend on some underlying estimated behavioural state (although that’s not yet implemented).

The result is a map that shows where the individual could have spent more or less (or no) time over the time interval under construction. The main limitation of this approach is that reconstructs where the individual could have been, but not where it was. In reality, the individual’s current position constrains where it can go next. The ACDCMP algorithm is an extension of this approach that incorporates a movement model for this reason.
}
\examples{
#### Step (1) Implement setup_acdc_*() steps
# ... Define acoustic centroids required for ACDC algorithm (see setup_acdc_centroids())

#### Step (2) Prepare movement time series for algorithm
# Add required columns to dataframes:
dat_acoustics$timestamp_num <- as.numeric(dat_acoustics$timestamp)
dat_archival$timestamp_num  <- as.numeric(dat_archival$timestamp)
# Focus on an example individual
id <- 25
acc <- dat_acoustics[dat_acoustics$individual_id == id, ]
arc <- dat_archival[dat_archival$individual_id == id, ]
# Focus on the subset of data for which we have both acoustic and archival detections
acc <- acc[acc$timestamp >= min(arc$timestamp) - 2*60 &
             acc$timestamp <= max(arc$timestamp) + 2*60, ]
arc <- arc[arc$timestamp >= min(acc$timestamp) - 2*60 &
             arc$timestamp <= max(acc$timestamp) + 2*60, ]
# We'll focus on a one day period with overlapping detection/depth time series for speed
end <- as.POSIXct("2016-03-18")
acc <- acc[acc$timestamp <= end, ]
arc <- arc[arc$timestamp <= end, ]
arc <- arc[arc$timestamp >= min(acc$timestamp) - 2*60 &
             arc$timestamp <= max(acc$timestamp) + 2*60, ]

#### Example (1) Implement ACDC algorithm with default arguments
# This implements the algorithm on a single core, printing messages
# ... to the console to monitor function progress.
out_acdc <- acdc(acoustics = acc,
                 archival = arc,
                 bathy = dat_gebco,
                 detection_range = 425,
                 mobility = 200,
                 depth_error = 2.5,
                 acc_centroids = dat_centroids
                 )
# The function returns a list with four elements
# ... .acdc contains the results of the algorithm, implemented by the back-end
# ... function .acdc(). The other elements provide the time series
# ... for each chunk, the time of the algorithm and a list of user inputs
summary(out_acdc)

#### Example (2): Write messages to file to monitor function progress via 'con'
out_acdc <- acdc(acoustics = acc,
                 archival = arc,
                 bathy = dat_gebco,
                 detection_range = 425,
                 mobility = 200,
                 depth_error = 2.5,
                 acc_centroids = dat_centroids,
                 con = tempdir()
                 )
acdc_log <- readLines(paste0(tempdir(), "/acdc_log.txt"))
utils::head(acdc_log, 10)
file.remove(paste0(tempdir(), "/acdc_log.txt"))

#### Example (3): Implement the algorithm and return plotting information
# Specify plot = NULL to include plotting information for all time steps
# ... or a vector to include this information for specific time steps
out_acdc <- acdc(acoustics = acc,
                 archival = arc,
                 bathy = dat_gebco,
                 detection_range = 425,
                 mobility = 200,
                 depth_error = 2.5,
                 acc_centroids = dat_centroids,
                 plot = NULL
                 )

#### Example (4): Implement the algorithm in parallel by supplying a cluster
# If verbose = TRUE (the default), it is necessary to specify a directory
# ... into which dot_acdc_log_*.txt files are saved (i.e., messages
# ... cannot be written to the console in parallel)
out_acdc <- acdc(acoustics = acc,
                 archival = arc,
                 bathy = dat_gebco,
                 detection_range = 425,
                 mobility = 200,
                 depth_error = 2.5,
                 acc_centroids = dat_centroids,
                 con = tempdir(),
                 cl = parallel::makeCluster(2L)
                 )
## Check logs
list.files(tempdir())
# "acdc_log.txt" contains the log for the overall function
acdc_log <- readLines(paste0(tempdir(), "/acdc_log.txt"))
head(acdc_log, 20)
# "acdc_log_1.txt", "acdc_log_2.txt" etc contain chunk-specific logs
acdc_log_1 <- readLines(paste0(tempdir(), "/dot_acdc_log_1.txt"))
utils::head(acdc_log_1)
utils::tail(acdc_log_1)
## Examine outputs
# Note that there are now four elements in .acdc, one for each chunk
# Likewise, there are four elements in four elements in ts_by_chunk,
# ... containing the movement time series for each chunk.
summary(out_acdc)
# Note that the last observation of each time series overlaps with the
# ... first observation for the next chunk, to prevent loss of information
lapply(out_acdc$ts_by_chunk,
  function(chunk) chunk$acoustics[c(1, nrow(chunk$acoustics)), ])

#### Example (5) Biologically meaningful chunks can be specified via
# .. the 'split' argument or by passing a list of acoustic time series
# .. already split by list of dataframes to 'acoustics'
## Using the split argument:
out_acdc <- acdc(acoustics = acc,
                 archival = arc,
                 bathy = dat_gebco,
                 detection_range = 425,
                 mobility = 200,
                 depth_error = 2.5,
                 acc_centroids = dat_centroids,
                 con = tempdir(),
                 cl = parallel::makeCluster(2L),
                 split = "2 hours"
                 )
## Passing a list of dataframes
# This option can provide more flexibility than split, which only
# ... understands time categories supported by lubridate::floor_date()
# ... This example could also be used using split, as described above,
# ... but this is not the case for all time categories (e.g., seasons).
acc$chunk <- cut(acc$timestamp, "2 hours")
acc_ls <- split(acc, acc$chunk)
out_acdc <- acdc(acoustics = acc_ls,
                 archival = arc,
                 bathy = dat_gebco,
                 detection_range = 425,
                 mobility = 200,
                 depth_error = 2.5,
                 acc_centroids = dat_centroids,
                 con = tempdir(),
                 cl = parallel::makeCluster(2L)
                 )

#### Example (5) Implement the algorithm for multiple individuals
# ... To do this, it is necessary to apply the function iteratively
# ... to each individual.
# Pre-processing to define computation time
# ... E.g., careful definition of time series
# ... E.g., define 'map' argument
map <- dat_gebco
map <- raster::setValues(map, 0)
# Define cluster
cluster <- FALSE
if(cluster){
  cl <- parallel::makeCluster(2L)
  parallel::clusterExport(cl = cl, varlist = c("acdc",
                                               "dat_archival",
                                               "dat_gebco",
                                               "map",
                                               "dat_centroids"
                                                ))
} else cl<- NULL
# Implement algorithm for each individual
acdc_out_by_id <-
  pbapply::pblapply(split(dat_acoustics, dat_acoustics$individual_id), cl = cl, function(acc){
    # Define individual-specific folder in which to save function logs
    dir_global <- paste0(tempdir(), "/")
    dir_id     <- paste0(dir_global, acc$individual_id[1], "/")
    if(!dir.exists(dir_id)) dir.create(dir_id)
    # Focus on a small sample of time series for speed
    acc <- acc[1:3, ]
    # Isolate archival data for individual
    arc <- dat_archival[dat_archival$individual_id == acc$id[1], ]
    # Implement algorithm
    acdc_out <- acdc(acoustics = acc,
                     archival = dat_archival,
                     bathy = dat_gebco,
                     map = map,
                     detection_range = 425,
                     mobility = 200,
                     depth_error = 2.5,
                     acc_centroids = dat_centroids,
                     plot = 1:10L,
                     con = dir_id
                     )
    # Include logs in output
    acdc_log <- lapply(list.files(dir_id, full.names = TRUE), readLines)
    # Simplify the results at this stage or outside of this loop
    # ... using acdc_simplify()
    # Return results for specified individual
    out <- list(acdc_id = acc$individual_id[1], acdc_out = acdc_out, acdc_log = acdc_log)
    return(out)
  })
if(!is.null(cl)) parallel::stopCluster(cl)
summary(acdc_out_by_id)

#### Step (3) Simplify the function outputs
# This step aggregates information across chunks, which is necessary to
# ... plot information aggregated across all chunks (see below).
# It is only necessary if the algorithm has been implemented chunk-wise
# ... see acdc_simplify()

#### Step (4) Examine function outputs, e.g., via plotting
# See acdc_plot() and acdc_animate() to visualise the results
# ... (either for a specific chunk or aggregated across all chunks
# ... using acdc_simplify() as described above).

}
\seealso{
The 'depth-contour' component of the algorithm can be implemented via \code{\link[flapper]{dc}}. For more information on the ACDC algorithm, see \code{\link[flapper]{acdc_setup_centroids}}, which defines the acoustic centroids required by this function; \code{\link[flapper]{.acdc}}, the back-end workhorse of this function; \code{\link[flapper]{acdc_simplify}} which simplifies the outputs of the \code{\link[flapper]{acdc}} function; and \code{\link[flapper]{acdc_plot}} and \code{\link[flapper]{acdc_animate}}, which visualise the results.
}
\author{
Edward Lavender
}
