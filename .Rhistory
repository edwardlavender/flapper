dplyr::select("date_time", "receiver", "receiver_number")
# print the first two records from the subsetted dataframe
print(head(d_sbt, 2))
# print the last two records
print(tail(d_sbt, 2))
# confirm all records lie outisde of dates of deployment and removal
# should always return TRUE
ifelse(nrow(moorings_sbt) == 1,
print(
table(d_sbt$date_time < moorings_sbt$time_operation_start_receiver[1] | d_sbt$date_time > moorings_sbt$time_operation_end_receiver[1])
),
print(
table(
d_sbt$date_time < moorings_sbt$time_operation_start_receiver[1] |
d_sbt$date_time > moorings_sbt$time_operation_end_receiver[1] & d_sbt$date_time < moorings_sbt$time_operation_start_receiver[2] |
d_sbt$date_time > moorings_sbt$time_operation_end_receiver[2])
)
)
# close the loop
}
# remove records with NA for receiver_name
# the above loop confirms these are all due to records outside of dates of deployment/removal
# JT recommends removing these data (default state of receivers is to be on)
# e.g. continue to record on the boat.
d <- d %>% filter(!is.na(receiver_number))
# final check: there are no records after the date of last retrieval of the receivers (good)
table(d$date_time > as.POSIXct("27-07-2017", format = "%d-%m-%Y"))
#################################################################
#### Remove all data on servicing days
head(d)
d$date <- as.Date(d$date_time)
d$service <- FALSE
servicing_ls <- mapply(servicing_ls, names(servicing_ls), FUN = function(s1, rid){
s1$receiver_number <- rid
return(s1)
}, SIMPLIFY = FALSE)
servicing <- servicing_ls %>% dplyr::bind_rows()
servicing$hour <- WeStCOMSExploreR::hour_dbl(servicing$timestamp)
range(servicing$hour) # from 7 am until 2 pm --> potentially inaccurate?
# TO BE COMPLETED.
#
#
#
#
#
#################################################################
### 7) All detections of acoustic codes that are not recorded in the skate ids dataframe will be removed
# ... this reflects ghost detections
# ... and also all records of the acoustic tags built into receivers will be removed
# ... (this data concentrates on skate movement)
# if all reduced acoustic ids have been specified correctly,
# then there are no other detections:
table(levels(d$reduced_acoustic_id) %ni% levels(skateids$reduced_acoustic_id))
# check for no confusion with tags built in having possibly had acoustic ids mis-specified
builtin <- substr(as.character(moorings$receiver_transmitter_acoustic_id), start= 3, stop=5)
builtin <- as.factor(builtin)
table(builtin %in% levels(skateids$reduced_acoustic_id)) # looks good.
#################################################################
#### False detections
#### glatos approach
tf <- 3600
det <- data.frame(detection_timestamp_utc = d$date_time,
transmitter_codespace = substr(d$transmitter, 1, 8),
transmitter_id = d$reduced_acoustic_id,
receiver_sn = d$receiver_number)
det <- glatos::min_lag(det)
det <- glatos::false_detections(det, tf = tf, show_plot = TRUE)
# The filter identified 850 (0.41%) of 208338 detections as potentially false.
#### The effects of incorporating spatial information
# Define distances between receivers
dist <- flapper::dist_btw_receivers(moorings = data.frame(ID = moorings$receiver_number,
lat = moorings$lat_receiver,
long = moorings$long_receiver))
head(dist); range(dist$dist)
# Implement false_detections_sf()
det2 <- flapper::false_detections_sf(det = det,
tf = tf,
sf = 5,
dist = dist)
det2_details <- attr(det2, "details")
det <- cbind(det, det2_details)
det_pass_sf <- det[det$passed_filter_sf == 1, ]
# View(det_pass_sf)
utils.add::basic_stats(det_pass_sf$dist_sf, na.rm = TRUE, output = "wdf")
# IQR  max mean  min  sd
# 0.46 2.71  0.8 0.39 0.3
#### Examine the false detections which failed the glatos and spatial filters
#### Approach: the treatment of false detections
# Plot the number of false detections with min lags
# ... less than a sequence of thresholds
# ... so we can see more easily the effect of the 1 hour cut off.
det_fail <- det[det$passed_filter_sf == 0, ]
n_less_than_th <- function(x, th) {
y <- as.numeric(table(x < th)["TRUE"] )
if(is.na(y)) y <- 0
return(y)
}
n_less_than_th <- Vectorize(n_less_than_th, "th")
y <- n_less_than_th(det_fail$min_lag, x)
plot.pretty::pretty_plot(x/60/60, y,
xlab = "min lag (hours)",
ylab = "No. 'false' detections",
type = "l",
lwd = 2)
# Results, quite a few 'false' detections were accompanied by detections
# ... within a few hours of that receiver. We should probably keep these
# ... based on limited detection ranges of receivers.
# ... A few false detections are accompanied by detections within ~ 12 hours
# ... It is very difficult to decide whether or not these are 'false'
# Perhaps we can (a) weight a false detection according to min_lag (or detections at nearby receivers?)
# ... or do two models of everything (one with, one without putative 'false' detections
# ... to see if they make a difference (probably they won't since they're such a small proportion
# ... of detections anyway))
# Need to decide on best approach to deal with these
#################################################################
#### 8) Filter based on the frequency of detections
run <- FALSE
if(run){
########## This section of code c. 45 minutes to run! ###########
# (45 mins if you use the progress bar to monitor loop progress)
# (65 mins if  you use print(i) to monitor loop progress)
# For each individiual detection,
# check if that same individual was detected at the same receiver in
# ... a 1 hour period around this detection (i.e. 30 min before, 30 min after)
# ... if it was, we'll keep this detection (i.e. valid)
# if it was not, check whether it was detected at any othher receivers in this time period
# ...if it was detected at other receivers within 5km, we'll keep this record
# ... (based on max estimated swimming speed in Neat et al)
# ... if it was not, we'll remove this record
# test
# i <- 1921
# create a blank column that will define whether or not we keep that record
d$keep <- rep(NA, nrow(d))
# define starting time (this may take a while)
t1 <- Sys.time()
# define a progress bar
pb <- txtProgressBar(min = 0, max = nrow(d), style = 3)
# for each row in the acoustics dataframe
for(i in 1:nrow(d)){
# print i
# print(i)
# remove out some objects from memory to avoid confusion as the loop repeats
if(i > 1){rm(acc_sbt, nrw_acc_sbt)}                     # created on every run of the loop after (i.e. always in memory after first run)
if("acc_sbt2" %in% list()){rm(acc_sbt2, nrw_acc_sbt2)}  # only created on some runs of the loop; sometimes in memory (hence if statement)
if("dists_sbt" %in% list()){rm(dists_sbt)}              # only created on some runs of the loop; sometimes in memory
# define a one hour interval around the time of detection
min_t <- d$date_time[i] - 60*30
max_t <- d$date_time[i] + 60*30
# identify the receiver and indiviual detected
rec <- d$receiver_number[i]
id <- d$reduced_acoustic_id[i]
# subset the dataframe to consider the receiver, individual and timeframe of interest
acc_sbt <-
d %>%
filter(
receiver_number == rec,
reduced_acoustic_id == id,
date_time >= min_t & date_time < max_t
)
# define number of rows
nrw_acc_sbt <- nrow(acc_sbt)
# print the last acc_sbt for checking:
if(i == nrow(d)){
print(acc_sbt)}
# if the subsetted dataframe contains more than one record (row), add 1 to the keep column
# if the subsetted dataframe constains less than one record in that hour, add 0
if(nrw_acc_sbt > 1){
d$keep[i] <- 1
}
# if that individual was only detected at that one specific receiver once,
# ... we need to check whether it was detected at any nearby receivers in the same 1hr period
# ... first subset the acoustic data to consider only the individual and the time period of interest
else if(nrw_acc_sbt == 1){
# create a new subsetted dataframe of that individual and that 1 hour period
acc_sbt2 <-
d %>%
filter(
reduced_acoustic_id == id,
date_time >= min_t & date_time < max_t
)
# define number of rows
nrw_acc_sbt2 <- nrow(acc_sbt2)
# if the individual was detected at other receivers in the same 1hr period,
# ...then we'll obtain the distances between the receiver at which the specific
# ... detection of interest was detected
# ... and any other receivers it was detected at in that one hour period
if(nrw_acc_sbt2 > 1){
# first define the number of unique receivers at which that individual was detected
# ... in the specified hour period
unique_rec <- unique(acc_sbt2$receiver_number)
# exclude receiver of interest
unique_rec <- unique_rec[-c(which(unique_rec == rec))]
# calculate the remaining number of unique receivers at which the individual was detected
n_unique_rec <- length(unique_rec)
# create a dataframe that contains the receiver of interest
# ... against all other receivers and a distance column that will
# ... contain the distance between the receiver at which the individual was detected
# ...and all other receivers at which the individual was detected in the same 1hr period
dists_sbt <- data.frame(receiver1 = rep(rec, n_unique_rec),
receiver2 = unique_rec,
dist      = rep(NA, n_unique_rec))
# for each row in this dataframe, we will add the distance between the receivers
# ... from the dists dataframe (created previously)
# ...(NB, there are two possible ways around in which the receiver can be ordered in dist)
for(j in 1:nrow(dists_sbt)){
dists_sbt$dist[j] <-
dists$dist[which(
dists$receiver1 == rec & dists$receiver2 == dists_sbt$receiver2[j] | # possibility one
dists$receiver1 == dists_sbt$receiver2[j] & dists$receiver2 == rec   # possibility two
)]
} # close for loop
# if the subsetted dataframe is only one record, but that individual was detected at another
# ... receiver in the same hour within 5 km of the uncertain receiver,
# ... we will also keep the detection
if(min(dists_sbt$dist) <= 5){
d$keep[i] <- 2 # 2 distinguished the records we've kept based on this second method
# print(paste("Decision made to keep a record based on acc_sbt2, row = ", i))
} # close 3rd if loop [min(dists_sbt$dist) <= 5]
# if nrw_acc_sbt == 1 and nrw_acc_sbt2 > 1 but min(dists_sbt$dist) > 5, then we will remove that record
else {
d$keep[i] <- 0 }
} # close 2nd if loop [nrw_acc_sbt2 > 1]
# if nrw_acc_sbt == 1 but nrw_acc_sbt2 is not > 1, we remove that record
# i.e. detections are removed when:
# an individual is detected at a specific receiver once in a one hour period
# and at no other closely associated receivers in the same one hour period
else {
d$keep[i] <- 0 }
} # close 1st if else statement [nrw_acc_sbt == 1]
# update progress bar
setTxtProgressBar(pb, i)
# close for loop
}
# check number of rows
nrow(d)
# define end time to look at how long this took:
t2 <- Sys.time()
# look at duration of task:
t2-t1
# Time difference of 43.40358 mins
# save dataframe (the above takes a long time to run)
setwd(paste0("/Users/el72/Documents/PhD/",
"Academic_PhD_Work/Data and Modelling/",
"Data/Processed Data/Basic Data Processed Outputs"))
write.csv(d, "acoustics_intermediate_processed_keepcolumn.csv", row.names = F)
# examine the outcomes of the quality checking progress for detections
qc_outcomes <- table(d$keep); qc_outcomes
# 1361  detections will be removed because they were the only detection at that receiver
# ....of that individual in a 1hr period and no detections at closely asscoaited receivers
# 214901 are kept because there was more than one detection of that individual at that  receiver in a 1hr period
# 277 detections are kept because, although there was only one detection of that individual
# ... at that receiver in a 1 hr perio
# ... that individual was detected at a closely associated receiver in the same 1hr period
# qc_outcomes
#      0      1      2
#     1361 214901    277
# check the percent of detections falling into each outcome:
pcs <- (qc_outcomes/sum(qc_outcomes))*100; pcs
# only keep detections allocated 1 or two (not 0)
d <- d %>% filter(keep %in% c(1, 2))
}
#################################################################
#### 9) Filtering out data around recaptures
# filter the recaptures dataframe to only include dates relevant for accoustic tagging;
# valid recaptures (i.e. recapture_include == "Y")
# and not deployment dates (we've dealt with those above)
recaptures <-
recaptures %>%
filter(relevance %in% c("both", "accoustic_only"),
recapture_include == "Y")
# For each individual and associated recapture date
# The aim is to remove all data from ca. 1 hr before recapture until midnight on that day
# In f_archival_data_processing.R, this was possible because we had depth records
# which we could use to estimate the precise time of recapture
# here, all acoustically tagged individuals are associated with a DST id
# see a_skateids_processed.R; search: skateids$reduced_acoustic_id[is.na(skateids$dst_id)]
# for some of the acoustic data, we could use these estimated times
# however, altrhough all individuals had dsts attached
# e.g. individual dst_id 1558
# to be consistent across all individuals in the acoustic data, a different approach is required
# for each individual and associated recapture data
# ... remove all data before 6am on that date until midnight
# ... this assumes recaptures occured at least 1 hour 6am on a given date
# create a blank vector in which we will store the number of rows removed for each recapture date:
lr <- rep(NA, nrow(recaptures))
# for each individual and associated recapture date in the recaptures dataframe
for(i in 1:nrow(recaptures)){
# print i (loop run number) and the number of rows in the acoustics dataframe
# this should decrease on each run of the loop as rows are removed
print(paste("Loop run number ", i))
print(paste("Number of rows in acoustics datafame: ", nrow(d)))
# define 6am on the day of recapture
tmin <- recaptures$date[i] + 60*60*6
# define midnight on the day of recapture
tmax <- recaptures$date[i] + 60*60*24
# identify the row numbers for this individual and this recapture date...
# that include data from 6am on the day of recapture
# and until midnight after this recapture time:
rows_to_remove <-
which(d$reduced_acoustic_id == recaptures$acoustic_id[i] &
d$date_time >= tmin &
d$date_time <= tmax)
# print number of rows that will be removed
print(paste("rows_to_remove ", length(rows_to_remove)))
# Define the length of the number of rows to remove
l <- length(rows_to_remove)
lr[i] <- l
# if there is a positive number of rows to remove (i.e. the which() statement does not return Integer(0))
if(l >0){
# print individual name and date of recapture event
print(recaptures$acoustic_id[i])
print(recaptures$date[i])
# print the rows to be removed (checking)
print(d[rows_to_remove, ] %>% select("date_time", "reduced_acoustic_id"))
# remove identified rows from archival, then repeat the loop
d <- d[-c(rows_to_remove), ]
# close if loop
}
# close for loop
}
# view the number of rows removed on  each date:
lr
# check the final number of rows in the acoustics dataframe
nrow(d)
#################################################################
#################################################################
#### Adding data from skateids and moorings
#################################################################
#### Add data from skateids (individual characteristics)
d$dst_id <- skateids$dst_id[match(d$reduced_acoustic_id, skateids$reduced_acoustic_id)]
d$sex <- skateids$sex[match(d$reduced_acoustic_id, skateids$reduced_acoustic_id)]
d$total_length <- skateids$total_length[match(d$reduced_acoustic_id, skateids$reduced_acoustic_id)]
d$disc_width <- skateids$disc_width[match(d$reduced_acoustic_id, skateids$reduced_acoustic_id)]
#################################################################
#### Add data from moorings (receiver characteristics)
# add operation deployment date
d$date_operation_start_receiver <-
moorings$date_operation_start_receiver[match(d$receiver_number, moorings$receiver_number)]
# add removal date to acoustics df:
d$date_operation_end_receiver <-
moorings$date_operation_end_receiver[match(d$receiver_number, moorings$receiver_number)]
# others
d$lat_receiver <- moorings$lat_receiver[match(d$receiver_number, moorings$receiver_number)]
d$long_receiver <- moorings$long_receiver[match(d$receiver_number, moorings$receiver_number)]
d$operation_duration <- moorings$operation_duration[match(d$receiver_number, moorings$receiver_number)]
d$receiver_depth <- moorings$receiver_depth[match(d$receiver_number, moorings$receiver_number)]
#################################################################
#### final dates processing based on receiver deployment/removal times:
# There shoud be no records of individuals before
# ... or after the day of deployment/removal (already dealt with above)
# but even on the day of appointment or removal
# there may be effects of deployment and removal that cause errors/disturb fish behaviour
# check the amount of date on the first day of deployment (until midnight):
table(d$date_time < d$date_operation_start_receiver)              # before day of deployment
table(d$date_time < as.POSIXct(d$date_operation_start_receiver) + 60*60*24)   # before midnight on day of deployment
# check the amount of data on after 6am on the final date of recording:
table(d$date_time > d$date_operation_end_receiver)                 # after day of removal
table(d$date_time > as.POSIXct(d$date_operation_end_receiver) - 60*60*18)      # after 6am on day of removal
# only include data that was collected from a receiver :
nrow(d)
d <- d %>%
# ... after midnight on the first day of deployment
filter(date_time > as.POSIXct(d$date_operation_start_receiver, tz = "UTC") + 60*60*24) %>%
# ... before 6am on the day of removal
filter(date_time < as.POSIXct(d$date_operation_end_receiver, tz = "UTC") - 60*60*18)
nrow(d)
#################################################################
#################################################################
#### Finalise dataframe
d <- d %>% select(
date_time,
date_time_numeric,
station_name,
receiver_number,
receiver,
lat_receiver,
long_receiver,
reduced_acoustic_id,
transmitter,
sensor_value,
sensor_unit,
sex,
total_length,
disc_width,
dst_id,
date_deployment_tag,
date_removal_tag_acc,
date_operation_start_receiver,
date_operation_end_receiver,
operation_duration,
receiver_depth
)
#################################################################
#################################################################
#### note that not all individuals tagged were ever detected
# 43 skate were tagged [check - differs from report!]:
length(levels(skateids$reduced_acoustic_id))
# these are the skate that were tagged:
levels(skateids$reduced_acoustic_id)
# 36 skate were detected:
length(levels(d$reduced_acoustic_id))
# these are the skate that were detected:
levels(d$reduced_acoustic_id)
# list of skate never detected:
levels(factor(
skateids$reduced_acoustic_id[which(
skateids$reduced_acoustic_id %ni% d$reduced_acoustic_id)]))
#################################################################
#################################################################
#### transmitters that also recorded depth n
# transmitters in the 200s also recorded depth, potentially enabling 3d geolocation
# create a smaller dataframe with transmitters that also recorded depth
td <-
d %>%
filter(as.numeric(reduced_acoustic_id) >= 200 &
as.numeric(reduced_acoustic_id) < 300)
td$reduced_acoustic_id <- factor(td$reduced_acoustic_id)
td$receiver <- factor(td$receiver)
# examine the duration for which these transmitters were at liberty
td$days <- td$date_removal_tag_acc - td$date_deployment_tag
td$days <- as.factor(td$days)
levels(td$days)
# below, save as a csv and import into QGIS to get a sense of distance between receivers
#################################################################
#################################################################
#### Save the resultant dataframe as a csv
setwd(paste0("/Users/el72/Documents/PhD/",
"Academic_PhD_Work/Data and Modelling/",
"Data/Processed Data/Basic Data Processed Outputs"))
saveRDS(d, "acoustics.rds")
# only include data that was collected from a receiver :
nrow(d)
d <- d %>%
# ... after midnight on the first day of deployment
filter(date_time > as.POSIXct(date_operation_start_receiver, tz = "UTC") + 60*60*24) %>%
# ... before 6am on the day of removal
filter(date_time < as.POSIXct(date_operation_end_receiver, tz = "UTC") - 60*60*18)
nrow(d)
d <- d %>% select(
date_time,
date_time_numeric,
station_name,
receiver_number,
receiver,
lat_receiver,
long_receiver,
reduced_acoustic_id,
transmitter,
sensor_value,
sensor_unit,
sex,
total_length,
disc_width,
dst_id,
date_deployment_tag,
date_removal_tag_acc,
date_operation_start_receiver,
date_operation_end_receiver,
operation_duration,
receiver_depth
)
# 43 skate were tagged [check - differs from report!]:
length(levels(skateids$reduced_acoustic_id))
# these are the skate that were tagged:
levels(skateids$reduced_acoustic_id)
# 36 skate were detected:
length(levels(d$reduced_acoustic_id))
# these are the skate that were detected:
levels(d$reduced_acoustic_id)
# list of skate never detected:
levels(factor(
skateids$reduced_acoustic_id[which(
skateids$reduced_acoustic_id %ni% d$reduced_acoustic_id)]))
# create a smaller dataframe with transmitters that also recorded depth
td <-
d %>%
filter(as.numeric(reduced_acoustic_id) >= 200 &
as.numeric(reduced_acoustic_id) < 300)
td$reduced_acoustic_id <- factor(td$reduced_acoustic_id)
td$receiver <- factor(td$receiver)
# examine the duration for which these transmitters were at liberty
td$days <- td$date_removal_tag_acc - td$date_deployment_tag
td$days <- as.factor(td$days)
levels(td$days)
setwd(paste0("/Users/el72/Documents/PhD/",
"Academic_PhD_Work/Data and Modelling/",
"Data/Processed Data/Basic Data Processed Outputs"))
saveRDS(d, "acoustics.rds")
head(d)
?image
?axis
devtools::document()
?compute_det_sim
?`date-time`
if(!(colnames(acoustics) %in% c("id", "timestamp", "long_receiver", "lat_receiver"))){
stop(paste0("acoustic_ls", [[i]], " does not contain all required column names."))
}
?`date_time`
date-time
?`date-time`
library(flapper)
?compute_det_sim
library(flapper)
library(flapper)
?compute_det_sim
library(flapper)
?compute_det_sim
?plot_det_sim
devtools::build_manual()
devtools::build_manua
devtools::build_manual
callr::rcmd
